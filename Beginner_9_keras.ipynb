{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "greek-township",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "\n",
    "# sklean\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, Flatten, MaxPooling2D, Dropout, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "\n",
    "# 不必要な警告を出さない設定\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# JupyterNotebook上でグラフを表示する設定\n",
    "%matplotlib inline\n",
    "# DataFrameで全ての列を表示する設定\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "opposed-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "submit_df = pd.read_csv('sample_submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "czech-compact",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>398</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.096264</td>\n",
       "      <td>0.822517</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3833</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>39.810590</td>\n",
       "      <td>0.204331</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4836</td>\n",
       "      <td>3</td>\n",
       "      <td>114</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.198760</td>\n",
       "      <td>0.521011</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4572</td>\n",
       "      <td>1</td>\n",
       "      <td>146</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.890259</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>636</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>90</td>\n",
       "      <td>26</td>\n",
       "      <td>140</td>\n",
       "      <td>40.270088</td>\n",
       "      <td>0.800513</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  \\\n",
       "0    398            0      126             80              0        0   \n",
       "1   3833            3       88             60             20        0   \n",
       "2   4836            3      114             76              0        0   \n",
       "3   4572            1      146             74              0        0   \n",
       "4    636            1      123             90             26      140   \n",
       "\n",
       "         BMI  DiabetesPedigreeFunction  Age  \n",
       "0  40.096264                  0.822517   21  \n",
       "1  39.810590                  0.204331   22  \n",
       "2  33.198760                  0.521011   21  \n",
       "3  26.890259                  0.504950   38  \n",
       "4  40.270088                  0.800513   28  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "built-colonial",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = train_df[0:1999]\n",
    "#test_df = test_df[0:1999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dedicated-davis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "2000\n",
      "1999\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(test_df))\n",
    "print(len(submit_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tutorial-guard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   index                     3000 non-null   int64  \n",
      " 1   Pregnancies               3000 non-null   int64  \n",
      " 2   Glucose                   3000 non-null   int64  \n",
      " 3   BloodPressure             3000 non-null   int64  \n",
      " 4   SkinThickness             3000 non-null   int64  \n",
      " 5   Insulin                   3000 non-null   int64  \n",
      " 6   BMI                       3000 non-null   float64\n",
      " 7   DiabetesPedigreeFunction  3000 non-null   float64\n",
      " 8   Age                       3000 non-null   int64  \n",
      " 9   Outcome                   3000 non-null   int64  \n",
      "dtypes: float64(2), int64(8)\n",
      "memory usage: 234.5 KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "packed-bleeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                       0\n",
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "written-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "further-trade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>9</td>\n",
       "      <td>125</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.536910</td>\n",
       "      <td>0.444902</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3832</td>\n",
       "      <td>4</td>\n",
       "      <td>109</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.047673</td>\n",
       "      <td>0.238243</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4927</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>78</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>52.371341</td>\n",
       "      <td>0.279471</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4088</td>\n",
       "      <td>9</td>\n",
       "      <td>125</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.062688</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3644</td>\n",
       "      <td>5</td>\n",
       "      <td>107</td>\n",
       "      <td>78</td>\n",
       "      <td>44</td>\n",
       "      <td>284</td>\n",
       "      <td>52.935068</td>\n",
       "      <td>0.284959</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  \\\n",
       "0    200            9      125             74              0        0   \n",
       "1   3832            4      109             80              0        0   \n",
       "2   4927            4       88             78             39        0   \n",
       "3   4088            9      125             74              0        0   \n",
       "4   3644            5      107             78             44      284   \n",
       "\n",
       "         BMI  DiabetesPedigreeFunction  Age  Outcome  \n",
       "0  28.536910                  0.444902   45        1  \n",
       "1  28.047673                  0.238243   22        0  \n",
       "2  52.371341                  0.279471   26        0  \n",
       "3  40.062688                  0.203922   45        0  \n",
       "4  52.935068                  0.284959   45        1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rubber-proof",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2492.964667</td>\n",
       "      <td>3.557000</td>\n",
       "      <td>113.733667</td>\n",
       "      <td>68.743667</td>\n",
       "      <td>11.164000</td>\n",
       "      <td>11.663333</td>\n",
       "      <td>35.262073</td>\n",
       "      <td>0.400476</td>\n",
       "      <td>28.932000</td>\n",
       "      <td>0.239000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1447.218078</td>\n",
       "      <td>3.032131</td>\n",
       "      <td>20.885612</td>\n",
       "      <td>16.332755</td>\n",
       "      <td>14.351159</td>\n",
       "      <td>45.064090</td>\n",
       "      <td>7.568025</td>\n",
       "      <td>0.274666</td>\n",
       "      <td>8.469078</td>\n",
       "      <td>0.426544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.145844</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1218.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.301920</td>\n",
       "      <td>0.230987</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2465.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.835873</td>\n",
       "      <td>0.268674</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3750.250000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.578256</td>\n",
       "      <td>0.506778</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4999.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>579.000000</td>\n",
       "      <td>53.400629</td>\n",
       "      <td>2.302072</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index  Pregnancies      Glucose  BloodPressure  SkinThickness  \\\n",
       "count  3000.000000  3000.000000  3000.000000    3000.000000    3000.000000   \n",
       "mean   2492.964667     3.557000   113.733667      68.743667      11.164000   \n",
       "std    1447.218078     3.032131    20.885612      16.332755      14.351159   \n",
       "min       0.000000     0.000000    57.000000       0.000000       0.000000   \n",
       "25%    1218.750000     1.000000   100.000000      64.000000       0.000000   \n",
       "50%    2465.500000     3.000000   111.000000      70.000000       0.000000   \n",
       "75%    3750.250000     6.000000   125.000000      78.000000      24.000000   \n",
       "max    4999.000000    13.000000   196.000000     110.000000      49.000000   \n",
       "\n",
       "           Insulin          BMI  DiabetesPedigreeFunction          Age  \\\n",
       "count  3000.000000  3000.000000               3000.000000  3000.000000   \n",
       "mean     11.663333    35.262073                  0.400476    28.932000   \n",
       "std      45.064090     7.568025                  0.274666     8.469078   \n",
       "min       0.000000     0.000775                  0.145844    21.000000   \n",
       "25%       0.000000    32.301920                  0.230987    22.000000   \n",
       "50%       0.000000    33.835873                  0.268674    26.000000   \n",
       "75%       0.000000    39.578256                  0.506778    33.000000   \n",
       "max     579.000000    53.400629                  2.302072    67.000000   \n",
       "\n",
       "           Outcome  \n",
       "count  3000.000000  \n",
       "mean      0.239000  \n",
       "std       0.426544  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "square-creek",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003418</td>\n",
       "      <td>0.036222</td>\n",
       "      <td>0.024221</td>\n",
       "      <td>-0.005473</td>\n",
       "      <td>0.004264</td>\n",
       "      <td>-0.022387</td>\n",
       "      <td>0.027093</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.010270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pregnancies</th>\n",
       "      <td>0.003418</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.067360</td>\n",
       "      <td>-0.008811</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>-0.034456</td>\n",
       "      <td>0.011715</td>\n",
       "      <td>-0.027216</td>\n",
       "      <td>0.421213</td>\n",
       "      <td>0.197909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose</th>\n",
       "      <td>0.036222</td>\n",
       "      <td>0.067360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007822</td>\n",
       "      <td>0.022918</td>\n",
       "      <td>0.010135</td>\n",
       "      <td>0.013754</td>\n",
       "      <td>0.053021</td>\n",
       "      <td>0.035148</td>\n",
       "      <td>0.064677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BloodPressure</th>\n",
       "      <td>0.024221</td>\n",
       "      <td>-0.008811</td>\n",
       "      <td>0.007822</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042476</td>\n",
       "      <td>0.040159</td>\n",
       "      <td>0.242601</td>\n",
       "      <td>0.098362</td>\n",
       "      <td>0.023235</td>\n",
       "      <td>0.051347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkinThickness</th>\n",
       "      <td>-0.005473</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.022918</td>\n",
       "      <td>0.042476</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.167506</td>\n",
       "      <td>0.092715</td>\n",
       "      <td>0.141789</td>\n",
       "      <td>0.028481</td>\n",
       "      <td>0.001112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insulin</th>\n",
       "      <td>0.004264</td>\n",
       "      <td>-0.034456</td>\n",
       "      <td>0.010135</td>\n",
       "      <td>0.040159</td>\n",
       "      <td>0.167506</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.168287</td>\n",
       "      <td>0.219013</td>\n",
       "      <td>0.047494</td>\n",
       "      <td>0.079457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>-0.022387</td>\n",
       "      <td>0.011715</td>\n",
       "      <td>0.013754</td>\n",
       "      <td>0.242601</td>\n",
       "      <td>0.092715</td>\n",
       "      <td>0.168287</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.067524</td>\n",
       "      <td>0.082661</td>\n",
       "      <td>0.244350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <td>0.027093</td>\n",
       "      <td>-0.027216</td>\n",
       "      <td>0.053021</td>\n",
       "      <td>0.098362</td>\n",
       "      <td>0.141789</td>\n",
       "      <td>0.219013</td>\n",
       "      <td>0.067524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.072471</td>\n",
       "      <td>0.099075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.421213</td>\n",
       "      <td>0.035148</td>\n",
       "      <td>0.023235</td>\n",
       "      <td>0.028481</td>\n",
       "      <td>0.047494</td>\n",
       "      <td>0.082661</td>\n",
       "      <td>0.072471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.266000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outcome</th>\n",
       "      <td>0.010270</td>\n",
       "      <td>0.197909</td>\n",
       "      <td>0.064677</td>\n",
       "      <td>0.051347</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.079457</td>\n",
       "      <td>0.244350</td>\n",
       "      <td>0.099075</td>\n",
       "      <td>0.266000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             index  Pregnancies   Glucose  BloodPressure  \\\n",
       "index                     1.000000     0.003418  0.036222       0.024221   \n",
       "Pregnancies               0.003418     1.000000  0.067360      -0.008811   \n",
       "Glucose                   0.036222     0.067360  1.000000       0.007822   \n",
       "BloodPressure             0.024221    -0.008811  0.007822       1.000000   \n",
       "SkinThickness            -0.005473     0.003640  0.022918       0.042476   \n",
       "Insulin                   0.004264    -0.034456  0.010135       0.040159   \n",
       "BMI                      -0.022387     0.011715  0.013754       0.242601   \n",
       "DiabetesPedigreeFunction  0.027093    -0.027216  0.053021       0.098362   \n",
       "Age                       0.015610     0.421213  0.035148       0.023235   \n",
       "Outcome                   0.010270     0.197909  0.064677       0.051347   \n",
       "\n",
       "                          SkinThickness   Insulin       BMI  \\\n",
       "index                         -0.005473  0.004264 -0.022387   \n",
       "Pregnancies                    0.003640 -0.034456  0.011715   \n",
       "Glucose                        0.022918  0.010135  0.013754   \n",
       "BloodPressure                  0.042476  0.040159  0.242601   \n",
       "SkinThickness                  1.000000  0.167506  0.092715   \n",
       "Insulin                        0.167506  1.000000  0.168287   \n",
       "BMI                            0.092715  0.168287  1.000000   \n",
       "DiabetesPedigreeFunction       0.141789  0.219013  0.067524   \n",
       "Age                            0.028481  0.047494  0.082661   \n",
       "Outcome                        0.001112  0.079457  0.244350   \n",
       "\n",
       "                          DiabetesPedigreeFunction       Age   Outcome  \n",
       "index                                     0.027093  0.015610  0.010270  \n",
       "Pregnancies                              -0.027216  0.421213  0.197909  \n",
       "Glucose                                   0.053021  0.035148  0.064677  \n",
       "BloodPressure                             0.098362  0.023235  0.051347  \n",
       "SkinThickness                             0.141789  0.028481  0.001112  \n",
       "Insulin                                   0.219013  0.047494  0.079457  \n",
       "BMI                                       0.067524  0.082661  0.244350  \n",
       "DiabetesPedigreeFunction                  1.000000  0.072471  0.099075  \n",
       "Age                                       0.072471  1.000000  0.266000  \n",
       "Outcome                                   0.099075  0.266000  1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "engaged-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.hist(figsize=(20,20), color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "configured-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 説明変数⇒X、目的変数⇒Y\n",
    "\n",
    "X = train_df[['Pregnancies', 'BMI', 'DiabetesPedigreeFunction']]\n",
    "Y = train_df['Outcome']\n",
    "XT = test_df[['Pregnancies', 'BMI', 'DiabetesPedigreeFunction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "thick-fifteen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 3)\n",
      "(3000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "monthly-congress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリー変数への展開\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "Y1 = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "appreciated-coordinator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 3)\n",
      "(3000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "rolled-archive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1920, 3) Y_train: (1920, 2)\n",
      "X_test: (600, 3) Y_test: (600, 2)\n",
      "X_valid: (480, 3) Y_valid: (480, 2)\n"
     ]
    }
   ],
   "source": [
    "# データの分割\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y1, test_size=0.2, random_state=0)\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# 形状確認\n",
    "print(\"X_train:\", X_train.shape, \"Y_train:\", Y_train.shape)\n",
    "print(\"X_test:\", X_test.shape, \"Y_test:\", Y_test.shape)\n",
    "print(\"X_valid:\", X_valid.shape, \"Y_valid:\", Y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-serial",
   "metadata": {},
   "source": [
    "# モデルの初期化\n",
    "model = keras.Sequential()\n",
    "\n",
    "# 入力層\n",
    "model.add(Dense(32, activation='relu', input_shape=(8,)))\n",
    "\n",
    "# 隠れ層\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "# 隠れ層\n",
    "model.add(Dense(4, activation='relu'))\n",
    "\n",
    "# 出力層\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "# モデルの構築\n",
    "model.compile(optimizer = \"rmsprop\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "demonstrated-belize",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 14        \n",
      "=================================================================\n",
      "Total params: 80\n",
      "Trainable params: 80\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# モデルの初期化\n",
    "model = keras.Sequential()\n",
    "\n",
    "# 入力層\n",
    "model.add(Dense(6, activation='relu', input_shape=(3,)))\n",
    "\n",
    "\n",
    "# 隠れ層\n",
    "model.add(Dense(6, activation='relu'))\n",
    "\n",
    "# 出力層\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "# モデルの構築\n",
    "model.compile(optimizer = \"rmsprop\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "detected-looking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 8         \n",
      "=================================================================\n",
      "Total params: 53\n",
      "Trainable params: 53\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# モデルの初期化\n",
    "model = keras.Sequential()\n",
    "\n",
    "# 入力層\n",
    "model.add(Dense(6, activation='relu', input_shape=(3,)))\n",
    "\n",
    "\n",
    "# 隠れ層\n",
    "model.add(Dense(3, activation='relu'))\n",
    "\n",
    "# 出力層\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "# モデルの構築\n",
    "model.compile(optimizer = \"rmsprop\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "trained-metro",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "40/40 [==============================] - 2s 24ms/step - loss: 0.6851 - accuracy: 0.7544 - val_loss: 0.6685 - val_accuracy: 0.7625\n",
      "Epoch 2/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 0.7640 - val_loss: 0.6509 - val_accuracy: 0.7625\n",
      "Epoch 3/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6424 - accuracy: 0.7849 - val_loss: 0.6353 - val_accuracy: 0.7625\n",
      "Epoch 4/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6327 - accuracy: 0.7575 - val_loss: 0.6205 - val_accuracy: 0.7625\n",
      "Epoch 5/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6167 - accuracy: 0.7618 - val_loss: 0.6075 - val_accuracy: 0.7625\n",
      "Epoch 6/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6083 - accuracy: 0.7545 - val_loss: 0.5962 - val_accuracy: 0.7625\n",
      "Epoch 7/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.7590 - val_loss: 0.5862 - val_accuracy: 0.7625\n",
      "Epoch 8/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.7664 - val_loss: 0.5780 - val_accuracy: 0.7625\n",
      "Epoch 9/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7821 - val_loss: 0.5712 - val_accuracy: 0.7625\n",
      "Epoch 10/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.7532 - val_loss: 0.5653 - val_accuracy: 0.7625\n",
      "Epoch 11/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7672 - val_loss: 0.5601 - val_accuracy: 0.7625\n",
      "Epoch 12/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7713 - val_loss: 0.5564 - val_accuracy: 0.7625\n",
      "Epoch 13/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7642 - val_loss: 0.5534 - val_accuracy: 0.7625\n",
      "Epoch 14/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.7398 - val_loss: 0.5513 - val_accuracy: 0.7625\n",
      "Epoch 15/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7718 - val_loss: 0.5501 - val_accuracy: 0.7625\n",
      "Epoch 16/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7725 - val_loss: 0.5491 - val_accuracy: 0.7625\n",
      "Epoch 17/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7680 - val_loss: 0.5485 - val_accuracy: 0.7625\n",
      "Epoch 18/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7680 - val_loss: 0.5482 - val_accuracy: 0.7625\n",
      "Epoch 19/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7593 - val_loss: 0.5479 - val_accuracy: 0.7625\n",
      "Epoch 20/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7655 - val_loss: 0.5478 - val_accuracy: 0.7625\n",
      "Epoch 21/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.7571 - val_loss: 0.5477 - val_accuracy: 0.7625\n",
      "Epoch 22/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7633 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 23/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7694 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 24/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7796 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 25/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7631 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 26/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7647 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 27/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7690 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 28/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7638 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 29/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7723 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 30/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.7284 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 31/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7783 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 32/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7716 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 33/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7698 - val_loss: 0.5477 - val_accuracy: 0.7625\n",
      "Epoch 34/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7811 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 35/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7659 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 36/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7549 - val_loss: 0.5477 - val_accuracy: 0.7625\n",
      "Epoch 37/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7735 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 38/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7675 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 39/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7688 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 40/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7655 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 41/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7756 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 42/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7588 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 43/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7672 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 44/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7565 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 45/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7571 - val_loss: 0.5477 - val_accuracy: 0.7625\n",
      "Epoch 46/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7743 - val_loss: 0.5477 - val_accuracy: 0.7625\n",
      "Epoch 47/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7675 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 48/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7671 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 49/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7640 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 50/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7654 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 51/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7650 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 52/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7666 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 53/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7677 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 54/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7683 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 55/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7808 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 56/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.7532 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 57/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7740 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 58/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7620 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 59/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7530 - val_loss: 0.5476 - val_accuracy: 0.7625\n",
      "Epoch 60/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7873 - val_loss: 0.5475 - val_accuracy: 0.7625\n",
      "Epoch 61/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7773 - val_loss: 0.5475 - val_accuracy: 0.7625\n",
      "Epoch 62/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7618 - val_loss: 0.5475 - val_accuracy: 0.7625\n",
      "Epoch 63/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7645 - val_loss: 0.5475 - val_accuracy: 0.7625\n",
      "Epoch 64/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7686 - val_loss: 0.5475 - val_accuracy: 0.7625\n",
      "Epoch 65/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7636 - val_loss: 0.5475 - val_accuracy: 0.7625\n",
      "Epoch 66/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7669 - val_loss: 0.5475 - val_accuracy: 0.7625\n",
      "Epoch 67/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7718 - val_loss: 0.5475 - val_accuracy: 0.7625\n",
      "Epoch 68/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7653 - val_loss: 0.5475 - val_accuracy: 0.7625\n",
      "Epoch 69/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7605 - val_loss: 0.5475 - val_accuracy: 0.7625\n",
      "Epoch 70/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7655 - val_loss: 0.5474 - val_accuracy: 0.7625\n",
      "Epoch 71/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7607 - val_loss: 0.5474 - val_accuracy: 0.7625\n",
      "Epoch 72/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7612 - val_loss: 0.5474 - val_accuracy: 0.7625\n",
      "Epoch 73/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7612 - val_loss: 0.5474 - val_accuracy: 0.7625\n",
      "Epoch 74/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7714 - val_loss: 0.5474 - val_accuracy: 0.7625\n",
      "Epoch 75/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7745 - val_loss: 0.5474 - val_accuracy: 0.7625\n",
      "Epoch 76/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7693 - val_loss: 0.5474 - val_accuracy: 0.7625\n",
      "Epoch 77/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7650 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 78/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7753 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 79/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7787 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 80/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7767 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 81/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7647 - val_loss: 0.5474 - val_accuracy: 0.7625\n",
      "Epoch 82/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7558 - val_loss: 0.5474 - val_accuracy: 0.7625\n",
      "Epoch 83/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7689 - val_loss: 0.5474 - val_accuracy: 0.7625\n",
      "Epoch 84/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7683 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 85/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7748 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 86/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7788 - val_loss: 0.5474 - val_accuracy: 0.7625\n",
      "Epoch 87/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.7580 - val_loss: 0.5474 - val_accuracy: 0.7625\n",
      "Epoch 88/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7615 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 89/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7683 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 90/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7556 - val_loss: 0.5474 - val_accuracy: 0.7625\n",
      "Epoch 91/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7831 - val_loss: 0.5474 - val_accuracy: 0.7625\n",
      "Epoch 92/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7617 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 93/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7640 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 94/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7786 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 95/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7470 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 96/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7688 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 97/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7638 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 98/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7667 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 99/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.7534 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 100/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7694 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 101/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.7665 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 102/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.7564 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 103/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7731 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 104/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7687 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 105/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7695 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 106/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7700 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 107/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.7480 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 108/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7607 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 109/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7652 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 110/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7719 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 111/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7646 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 112/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7411 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 113/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7652 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 114/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7668 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 115/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7738 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 116/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7562 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 117/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7629 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 118/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7706 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 119/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7747 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 120/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7603 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 121/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7520 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 122/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7805 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 123/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7787 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 124/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7609 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 125/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7628 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 126/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7726 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 127/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7705 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 128/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7750 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 129/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7621 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 130/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7560 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 131/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7716 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 132/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7640 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 133/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7606 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 134/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7664 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 135/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7659 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 136/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7746 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 137/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7724 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 138/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7670 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 139/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7550 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 140/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7744 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 141/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7646 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 142/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7772 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 143/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7773 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 144/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7595 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 145/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7650 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 146/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7578 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 147/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7698 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 148/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.7669 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 149/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.7518 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 150/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7685 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 151/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7809 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 152/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7627 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 153/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7607 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 154/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7756 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 155/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7711 - val_loss: 0.5471 - val_accuracy: 0.7625\n",
      "Epoch 156/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.7656 - val_loss: 0.5471 - val_accuracy: 0.7625\n",
      "Epoch 157/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.7588 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 158/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7659 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 159/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7708 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 160/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7655 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 161/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7646 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 162/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7600 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 163/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7584 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 164/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7797 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 165/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7464 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 166/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7747 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 167/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7624 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 168/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7742 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 169/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7670 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 170/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7483 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 171/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7726 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 172/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7732 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 173/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7653 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 174/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.7741 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 175/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7717 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 176/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7712 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 177/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7611 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 178/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7744 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 179/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7747 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 180/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7720 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 181/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7414 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 182/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7565 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 183/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7808 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 184/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.7471 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 185/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7745 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 186/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7738 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 187/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7702 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 188/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7766 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 189/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7604 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 190/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7674 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 191/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7834 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 192/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7543 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 193/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7598 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 194/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.7701 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 195/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7656 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 196/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7645 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 197/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.7527 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 198/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7635 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 199/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7746 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 200/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7570 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 201/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7651 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 202/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7728 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 203/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7696 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 204/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7818 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 205/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7597 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 206/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7648 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 207/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7600 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 208/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7644 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 209/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7490 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 210/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7531 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 211/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7639 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 212/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7526 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 213/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.7678 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 214/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7688 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 215/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7742 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 216/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7659 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 217/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7617 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 218/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7799 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 219/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7544 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 220/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7634 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 221/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7675 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 222/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7719 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 223/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7662 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 224/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7488 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 225/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7643 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 226/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7666 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 227/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7808 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 228/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7635 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 229/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7797 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 230/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7637 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 231/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7559 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 232/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7864 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 233/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7657 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 234/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7647 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 235/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7720 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 236/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7785 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 237/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7602 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 238/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7750 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 239/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7856 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 240/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7720 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 241/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7677 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 242/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7640 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 243/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7569 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 244/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7708 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 245/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7738 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 246/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7549 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 247/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7526 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 248/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7603 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 249/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7739 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 250/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7597 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 251/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7602 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 252/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7673 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 253/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7725 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 254/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7665 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 255/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7675 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 256/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7701 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 257/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7682 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 258/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.7442 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 259/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7645 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 260/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7677 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 261/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7800 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 262/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7712 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 263/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7724 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 264/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7716 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 265/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7664 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 266/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7584 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 267/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7675 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 268/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7725 - val_loss: 0.5472 - val_accuracy: 0.7625\n",
      "Epoch 269/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7559 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 270/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7706 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 271/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7616 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 272/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7662 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 273/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7652 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 274/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7742 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 275/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7767 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 276/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7574 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 277/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7677 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 278/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7683 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 279/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.7526 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 280/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7587 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 281/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7618 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 282/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7583 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 283/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7569 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 284/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7812 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 285/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7784 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 286/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7728 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 287/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.7523 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 288/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7762 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 289/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7634 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 290/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7681 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 291/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7557 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 292/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7743 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 293/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7643 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 294/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7627 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 295/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7743 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 296/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7678 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 297/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7625 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 298/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7698 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 299/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7568 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Epoch 300/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7708 - val_loss: 0.5473 - val_accuracy: 0.7625\n",
      "Wall time: 24.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "log = model.fit(X_train, Y_train, epochs=300, batch_size=48, verbose=True,\n",
    "                callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                        min_delta=0, patience=300, \n",
    "                                                         verbose=1)],\n",
    "               validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "injured-rachel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# グラフ表示\n",
    "plt.plot(log.history['loss'], label='loss')          #学習データ\n",
    "plt.plot(log.history['val_loss'], label='val_loss')  #検証データ\n",
    "plt.legend(frameon=False) # 凡例の表示\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"crossentropy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cloudy-appliance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 予測\n",
    "Y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sexual-supervisor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# カテゴリー変数の復元\n",
    "Y_test_ = np.argmax(Y_test, axis=1)\n",
    "Y_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "outstanding-intake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       446\n",
      "           1       0.00      0.00      0.00       154\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.37      0.50      0.43       600\n",
      "weighted avg       0.55      0.74      0.63       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# モデルの評価\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Y_test_, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "legendary-reviewer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "予測率: 74.33333333333333 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_true=Y_test_, y_pred=Y_pred)\n",
    "print(\"予測率:\", accuracy*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "corresponding-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出ファイル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "first-island",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = XT  # 提出ファイル\n",
    "# 結果\n",
    "X_pred = np.array(data)\n",
    "# 予測\n",
    "y_pred = np.argmax(model.predict(X_pred), axis=1)  # X_predで予測データ全てが抽出できる\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "urban-niger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "Submit = test_df.loc[:,[\"index\"]]\n",
    "print(len(Submit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adaptive-oxford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "given-palestine",
   "metadata": {},
   "outputs": [],
   "source": [
    "Submit['pred'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "creative-persian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2000\n",
       "Name: pred, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Submit['pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "reserved-preliminary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>398</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4572</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>3138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>3294</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>3073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>361</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  pred\n",
       "0       398     0\n",
       "1      3833     0\n",
       "2      4836     0\n",
       "3      4572     0\n",
       "4       636     0\n",
       "...     ...   ...\n",
       "1995   3138     0\n",
       "1996    191     0\n",
       "1997   3294     0\n",
       "1998   3073     0\n",
       "1999    361     0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cognitive-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "Submit.to_csv(\"submit_8.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-intermediate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-cleaners",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "confidential-conditioning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>9</td>\n",
       "      <td>125</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.536910</td>\n",
       "      <td>0.444902</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3832</td>\n",
       "      <td>4</td>\n",
       "      <td>109</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.047673</td>\n",
       "      <td>0.238243</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4927</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>78</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>52.371341</td>\n",
       "      <td>0.279471</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4088</td>\n",
       "      <td>9</td>\n",
       "      <td>125</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.062688</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3644</td>\n",
       "      <td>5</td>\n",
       "      <td>107</td>\n",
       "      <td>78</td>\n",
       "      <td>44</td>\n",
       "      <td>284</td>\n",
       "      <td>52.935068</td>\n",
       "      <td>0.284959</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  \\\n",
       "0    200            9      125             74              0        0   \n",
       "1   3832            4      109             80              0        0   \n",
       "2   4927            4       88             78             39        0   \n",
       "3   4088            9      125             74              0        0   \n",
       "4   3644            5      107             78             44      284   \n",
       "\n",
       "         BMI  DiabetesPedigreeFunction  Age  Outcome  \n",
       "0  28.536910                  0.444902   45        1  \n",
       "1  28.047673                  0.238243   22        0  \n",
       "2  52.371341                  0.279471   26        0  \n",
       "3  40.062688                  0.203922   45        0  \n",
       "4  52.935068                  0.284959   45        1  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('train.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "rolled-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 説明変数⇒X、目的変数⇒Y\n",
    "\n",
    "x = df1.BMI\n",
    "y = df1.Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "precise-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データ7割、テストデータ3割に分割する \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "reliable-wrist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVCの分類モデルを作成\n",
    "from sklearn import linear_model\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(X_train.values.reshape(-1, 1), y_train.values.reshape(-1, 1))\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = \"linear\", gamma = \"scale\")\n",
    "classifier.fit(X_train.values.reshape(-1, 1), y_train.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "religious-finder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n"
     ]
    }
   ],
   "source": [
    "# 訓練データを回帰モデルに設定\n",
    "y_pred = classifier.predict(X_test.values.reshape(-1, 1))\n",
    "y_pred\n",
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "stuck-advice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n"
     ]
    }
   ],
   "source": [
    "# 予測値を表示\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "indirect-attribute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7477777777777778\n"
     ]
    }
   ],
   "source": [
    "# 実際の値を表示\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "direct-lemon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[673   0]\n",
      " [227   0]]\n"
     ]
    }
   ],
   "source": [
    "# 混同行列で集計結果を表示\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "living-medline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86       673\n",
      "           1       0.00      0.00      0.00       227\n",
      "\n",
      "    accuracy                           0.75       900\n",
      "   macro avg       0.37      0.50      0.43       900\n",
      "weighted avg       0.56      0.75      0.64       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 正答率を表示\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-institution",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
